{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e13bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gradi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\gradi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gradi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gradi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461796a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                NaN   \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label : 1-fake, 0-real\n",
    "df = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467ee6b",
   "metadata": {},
   "source": [
    "Eliminare duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd98299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    558\n",
       "text      39\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf846ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['title'].notna() & df['text'].notna()]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26809ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr duplicate: 16300\n"
     ]
    }
   ],
   "source": [
    "duplicate_groups = df.groupby(['title', 'text','label'])\n",
    "duplicates = duplicate_groups.filter(lambda x: len(x) > 1)\n",
    "print(f\"Nr duplicate: {len(duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a4ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“You’re Not Welcome!” Obama As Welcome At Rose...</td>\n",
       "      <td>Roseberg residents and families of victims are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“You’re Not Welcome!” Obama As Welcome At Rose...</td>\n",
       "      <td>Roseberg residents and families of victims are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“You Ruined Your Own Communities, Don’t Ruin O...</td>\n",
       "      <td>- &lt; “You Ruined Your Own Communities, Don’t Ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“You Ruined Your Own Communities, Don’t Ruin O...</td>\n",
       "      <td>- &lt; “You Ruined Your Own Communities, Don’t Ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“YOU’RE HIRED!” Trump Pulls Unemployed Vet Fro...</td>\n",
       "      <td>No matter which candidate you support, this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“YOU’RE HIRED!” Trump Pulls Unemployed Vet Fro...</td>\n",
       "      <td>No matter which candidate you support, this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“Would You Rather Do A Job You Hate And Not Pa...</td>\n",
       "      <td>Filmmaker and patriot, Dennis Michael Lynch is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“Would You Rather Do A Job You Hate And Not Pa...</td>\n",
       "      <td>Filmmaker and patriot, Dennis Michael Lynch is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Wikileaks is the Mossad, Stupid, Not the Russ...</td>\n",
       "      <td>Russian experts collecting evidence of anti-go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Wikileaks is the Mossad, Stupid, Not the Russ...</td>\n",
       "      <td>Russian experts collecting evidence of anti-go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  “You’re Not Welcome!” Obama As Welcome At Rose...   \n",
       "1  “You’re Not Welcome!” Obama As Welcome At Rose...   \n",
       "2  “You Ruined Your Own Communities, Don’t Ruin O...   \n",
       "3  “You Ruined Your Own Communities, Don’t Ruin O...   \n",
       "4  “YOU’RE HIRED!” Trump Pulls Unemployed Vet Fro...   \n",
       "5  “YOU’RE HIRED!” Trump Pulls Unemployed Vet Fro...   \n",
       "6  “Would You Rather Do A Job You Hate And Not Pa...   \n",
       "7  “Would You Rather Do A Job You Hate And Not Pa...   \n",
       "8  “Wikileaks is the Mossad, Stupid, Not the Russ...   \n",
       "9  “Wikileaks is the Mossad, Stupid, Not the Russ...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Roseberg residents and families of victims are...      1  \n",
       "1  Roseberg residents and families of victims are...      1  \n",
       "2  - < “You Ruined Your Own Communities, Don’t Ru...      1  \n",
       "3  - < “You Ruined Your Own Communities, Don’t Ru...      1  \n",
       "4  No matter which candidate you support, this mo...      1  \n",
       "5  No matter which candidate you support, this mo...      1  \n",
       "6  Filmmaker and patriot, Dennis Michael Lynch is...      1  \n",
       "7  Filmmaker and patriot, Dennis Michael Lynch is...      1  \n",
       "8  Russian experts collecting evidence of anti-go...      1  \n",
       "9  Russian experts collecting evidence of anti-go...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_sorted = duplicates.sort_values(by='title', ascending=False).reset_index(drop=True)\n",
    "duplicates_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044bc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['title', 'text'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb4d5a",
   "metadata": {},
   "source": [
    "Eliminare spatii multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4026c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffe6a3",
   "metadata": {},
   "source": [
    "Pentru inceput voi 'sparge' textul intr-o lista de stringuri ca sa analizez dimensionalitatea stirilor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3042e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voi folosi wordpunct_tokenize deoarece word_tokenize \n",
    "#nu recunoaste punctuatia, iar in texte mai exista greseli de scriere(de exemplu lipsa spatiului dupa punctul de la finalul unei propozitii)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: str(x) if pd.notna(x) else \"\") #transformam in string daca e nan sau alt tip de date\n",
    "df['tokens'] = df['text'].apply(lambda x: [token for token in wordpunct_tokenize(x) if token.strip() != \"\"])  #validare sa nu am tokenuri goale\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: str(x) if pd.notna(x) else \"\")\n",
    "df['title_tokens'] = df['title'].apply(lambda x: [token for token in wordpunct_tokenize(x) if token.strip() != \"\"])\n",
    "\n",
    "df['tokens_count'] = df['tokens'].apply(lambda x: len(x))\n",
    "df['title_tokens_count'] = df['title_tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b5410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((df['tokens_count'] == 0).sum())\n",
    "print((df['title_tokens_count'] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f6ea0",
   "metadata": {},
   "source": [
    "529 stiri goale, le elimin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d7ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['tokens_count'] != 0]\n",
    "(df['tokens_count'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dcd69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(tokens):\n",
    "    clean = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        token = re.sub(r\"[^\\w\\d]\", \"\", token)  # litere si cifre\n",
    "        if len(token) > 2:\n",
    "            clean.append(token)\n",
    "    return clean\n",
    "\n",
    "df['clean_text'] = df['tokens'].apply(clean_tokens)\n",
    "df['clean_title'] = df['title_tokens'].apply(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bb601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_count'] = df['clean_text'].apply(lambda x: len(x))\n",
    "df['title_words_count'] = df['clean_title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f611d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print((df['words_count'] == 0).sum())\n",
    "print((df['title_words_count'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32978f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df[(df['words_count'] != 0) & (df['title_words_count'] != 0)]\n",
    "\n",
    "print((df['words_count'] == 0).sum())\n",
    "print((df['title_words_count'] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be02e9",
   "metadata": {},
   "source": [
    "Eliminare stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1abfa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "df['clean_text_without_stopwords'] = df['clean_text'].apply(lambda x: [word for word in x if word not in stop_words and len(word) > 2])\n",
    "df['clean_title_without_stopwords'] = df['clean_title'].apply(lambda x: [word for word in x if word not in stop_words and len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ae6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_count_without_stopwords'] = df['clean_text_without_stopwords'].apply(lambda x: len(x))\n",
    "df['title_words_count_without_stopwords'] = df['clean_text_without_stopwords'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e170d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print((df['words_count_without_stopwords'] == 0).sum())\n",
    "print((df['title_words_count_without_stopwords'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d21f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df[(df['words_count_without_stopwords'] != 0) & (df['title_words_count_without_stopwords'] != 0)]\n",
    "\n",
    "print((df['words_count_without_stopwords'] == 0).sum())\n",
    "print((df['title_words_count_without_stopwords'] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f6c52",
   "metadata": {},
   "source": [
    "Lemmatizare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4134dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_with_pos(tokens):\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    lemmatized_tokens = []\n",
    "    for word, tag in pos_tags:\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'  # substantiv\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'  # verb\n",
    "        elif tag.startswith('JJ'):\n",
    "            pos = 'a'  # adjectiv\n",
    "        else:\n",
    "            pos = 'n'  # substantiv (valoare implicita)\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1291cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lemmatized'] = df['clean_text_without_stopwords'].apply(lemmatize_with_pos)\n",
    "df['title_lemmatized'] = df['clean_title_without_stopwords'].apply(lemmatize_with_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5931526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                  Re: WE’RE NOT NASTY! Like all Democrats, Sally...\n",
       "text                                   WE’RE NOT NASTY! Why does Sally Kohn hate wome...\n",
       "label                                                                                  1\n",
       "tokens                                 [WE, ’, RE, NOT, NASTY, !, Why, does, Sally, K...\n",
       "title_tokens                           [Re, :, WE, ’, RE, NOT, NASTY, !, Like, all, D...\n",
       "tokens_count                                                                         319\n",
       "title_tokens_count                                                                    24\n",
       "clean_text                             [not, nasty, why, does, sally, kohn, hate, wom...\n",
       "clean_title                            [not, nasty, like, all, democrats, sally, kohn...\n",
       "words_count                                                                          212\n",
       "title_words_count                                                                     16\n",
       "clean_text_without_stopwords           [nasty, sally, kohn, hate, women, much, posted...\n",
       "clean_title_without_stopwords          [nasty, like, democrats, sally, kohn, proves, ...\n",
       "words_count_without_stopwords                                                        142\n",
       "title_words_count_without_stopwords                                                  142\n",
       "text_lemmatized                        [nasty, sally, kohn, hate, woman, much, post, ...\n",
       "title_lemmatized                       [nasty, like, democrat, sally, kohn, prof, lit...\n",
       "Name: 236, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a103872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                  Papua New Guinea starts dismantling detention ...\n",
       "text                                   SYDNEY (Reuters) - Papua New Guinea began dism...\n",
       "label                                                                                  0\n",
       "tokens                                 [SYDNEY, (, Reuters, ), -, Papua, New, Guinea,...\n",
       "title_tokens                           [Papua, New, Guinea, starts, dismantling, dete...\n",
       "tokens_count                                                                         613\n",
       "title_tokens_count                                                                    14\n",
       "clean_text                             [sydney, reuters, papua, new, guinea, began, d...\n",
       "clean_title                            [papua, new, guinea, starts, dismantling, dete...\n",
       "words_count                                                                          457\n",
       "title_words_count                                                                     12\n",
       "clean_text_without_stopwords           [sydney, reuters, papua, new, guinea, began, d...\n",
       "clean_title_without_stopwords          [papua, new, guinea, starts, dismantling, dete...\n",
       "words_count_without_stopwords                                                        329\n",
       "title_words_count_without_stopwords                                                  329\n",
       "text_lemmatized                        [sydney, reuters, papua, new, guinea, begin, d...\n",
       "title_lemmatized                       [papua, new, guinea, start, dismantle, detenti...\n",
       "Name: 32754, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[32456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ee9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'text', 'label', 'clean_text', 'clean_title', 'clean_text_without_stopwords', 'clean_title_without_stopwords', 'text_lemmatized', 'title_lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9097f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_text_without_stopwords</th>\n",
       "      <th>clean_title_without_stopwords</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>title_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[comment, expected, from, barack, obama, membe...</td>\n",
       "      <td>[law, enforcement, high, alert, following, thr...</td>\n",
       "      <td>[comment, expected, barack, obama, members, fy...</td>\n",
       "      <td>[law, enforcement, high, alert, following, thr...</td>\n",
       "      <td>[comment, expect, barack, obama, member, fyf91...</td>\n",
       "      <td>[law, enforcement, high, alert, follow, threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[now, most, the, demonstrators, gathered, last...</td>\n",
       "      <td>[unbelievable, obama, attorney, general, says,...</td>\n",
       "      <td>[demonstrators, gathered, last, night, exercis...</td>\n",
       "      <td>[unbelievable, obama, attorney, general, says,...</td>\n",
       "      <td>[demonstrator, gather, last, night, exercise, ...</td>\n",
       "      <td>[unbelievable, obama, attorney, general, say, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[dozen, politically, active, pastors, came, he...</td>\n",
       "      <td>[bobby, jindal, raised, hindu, uses, story, ch...</td>\n",
       "      <td>[dozen, politically, active, pastors, came, pr...</td>\n",
       "      <td>[bobby, jindal, raised, hindu, uses, story, ch...</td>\n",
       "      <td>[dozen, politically, active, pastor, come, pri...</td>\n",
       "      <td>[bobby, jindal, raise, hindu, us, story, chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, sarmat, missile, dubbed, satan, will, re...</td>\n",
       "      <td>[satan, russia, unvelis, image, its, terrifyin...</td>\n",
       "      <td>[sarmat, missile, dubbed, satan, replace, flie...</td>\n",
       "      <td>[satan, russia, unvelis, image, terrifying, ne...</td>\n",
       "      <td>[sarmat, missile, dub, satan, replace, fly, mi...</td>\n",
       "      <td>[satan, russia, unvelis, image, terrify, new, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, can, say, this, one, about, time, someon...</td>\n",
       "      <td>[about, time, christian, group, sues, amazon, ...</td>\n",
       "      <td>[say, one, time, someone, sued, southern, pove...</td>\n",
       "      <td>[time, christian, group, sues, amazon, splc, d...</td>\n",
       "      <td>[say, one, time, someone, sue, southern, pover...</td>\n",
       "      <td>[time, christian, group, sue, amazon, splc, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "2  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "3  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "4  About Time! Christian Group Sues Amazon and SP...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  No comment is expected from Barack Obama Membe...      1   \n",
       "1  Now, most of the demonstrators gathered last n...      1   \n",
       "2  A dozen politically active pastors came here f...      0   \n",
       "3  The RS-28 Sarmat missile, dubbed Satan 2, will...      1   \n",
       "4  All we can say on this one is it s about time ...      1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [comment, expected, from, barack, obama, membe...   \n",
       "1  [now, most, the, demonstrators, gathered, last...   \n",
       "2  [dozen, politically, active, pastors, came, he...   \n",
       "3  [the, sarmat, missile, dubbed, satan, will, re...   \n",
       "4  [all, can, say, this, one, about, time, someon...   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0  [law, enforcement, high, alert, following, thr...   \n",
       "1  [unbelievable, obama, attorney, general, says,...   \n",
       "2  [bobby, jindal, raised, hindu, uses, story, ch...   \n",
       "3  [satan, russia, unvelis, image, its, terrifyin...   \n",
       "4  [about, time, christian, group, sues, amazon, ...   \n",
       "\n",
       "                        clean_text_without_stopwords  \\\n",
       "0  [comment, expected, barack, obama, members, fy...   \n",
       "1  [demonstrators, gathered, last, night, exercis...   \n",
       "2  [dozen, politically, active, pastors, came, pr...   \n",
       "3  [sarmat, missile, dubbed, satan, replace, flie...   \n",
       "4  [say, one, time, someone, sued, southern, pove...   \n",
       "\n",
       "                       clean_title_without_stopwords  \\\n",
       "0  [law, enforcement, high, alert, following, thr...   \n",
       "1  [unbelievable, obama, attorney, general, says,...   \n",
       "2  [bobby, jindal, raised, hindu, uses, story, ch...   \n",
       "3  [satan, russia, unvelis, image, terrifying, ne...   \n",
       "4  [time, christian, group, sues, amazon, splc, d...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  [comment, expect, barack, obama, member, fyf91...   \n",
       "1  [demonstrator, gather, last, night, exercise, ...   \n",
       "2  [dozen, politically, active, pastor, come, pri...   \n",
       "3  [sarmat, missile, dub, satan, replace, fly, mi...   \n",
       "4  [say, one, time, someone, sue, southern, pover...   \n",
       "\n",
       "                                    title_lemmatized  \n",
       "0  [law, enforcement, high, alert, follow, threat...  \n",
       "1  [unbelievable, obama, attorney, general, say, ...  \n",
       "2  [bobby, jindal, raise, hindu, us, story, chris...  \n",
       "3  [satan, russia, unvelis, image, terrify, new, ...  \n",
       "4  [time, christian, group, sue, amazon, splc, de...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a302fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df['z_score'] = zscore(df['words_count'])\n",
    "print((df['z_score'] >=3).sum())\n",
    "print((df['z_score'] < -3).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df[df['z_score'] < 3]\n",
    "print((df['z_score'] >=3).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00555c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32c1ba",
   "metadata": {},
   "source": [
    "Pentru fiecare coloana contine siruri de strings, se va folosi .apply(lambda x: eval(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
